{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2733, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>place</th>\n",
       "      <th>source</th>\n",
       "      <th>depth_log</th>\n",
       "      <th>lat_offset</th>\n",
       "      <th>lon_offset</th>\n",
       "      <th>year</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>rolling_count_7d</th>\n",
       "      <th>rolling_count_30d</th>\n",
       "      <th>rolling_mean_mag_30d</th>\n",
       "      <th>days_since_last_major</th>\n",
       "      <th>is_major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-09 02:29:26.690000+00:00</td>\n",
       "      <td>28.225</td>\n",
       "      <td>88.163</td>\n",
       "      <td>79.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>86 km NNW of Mangan, India</td>\n",
       "      <td>usgs</td>\n",
       "      <td>4.383276</td>\n",
       "      <td>-0.487576</td>\n",
       "      <td>3.192907</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3650.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-10 23:01:21.960000+00:00</td>\n",
       "      <td>26.559</td>\n",
       "      <td>86.663</td>\n",
       "      <td>68.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8 km WNW of R?jbir?j, Nepal</td>\n",
       "      <td>usgs</td>\n",
       "      <td>4.241327</td>\n",
       "      <td>-2.153576</td>\n",
       "      <td>1.692907</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1.855501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-30 15:06:26.080000+00:00</td>\n",
       "      <td>28.599</td>\n",
       "      <td>85.714</td>\n",
       "      <td>52.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>74 km NNW of Kod?ri??, Nepal</td>\n",
       "      <td>usgs</td>\n",
       "      <td>3.977811</td>\n",
       "      <td>-0.113576</td>\n",
       "      <td>0.743907</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.10</td>\n",
       "      <td>21.525687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-02-09 15:51:23.020000+00:00</td>\n",
       "      <td>29.925</td>\n",
       "      <td>80.730</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>20 km ENE of D?rchul?, Nepal</td>\n",
       "      <td>usgs</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>1.212424</td>\n",
       "      <td>-4.240093</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.60</td>\n",
       "      <td>31.556902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-02-21 07:21:17.300000+00:00</td>\n",
       "      <td>28.082</td>\n",
       "      <td>82.430</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14 km ESE of Tuls?pur, Nepal</td>\n",
       "      <td>usgs</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>-0.630576</td>\n",
       "      <td>-2.540093</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.55</td>\n",
       "      <td>43.202669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 dt     lat     lon  depth  mag                         place source  depth_log  lat_offset  lon_offset  \\\n",
       "0  1990-01-09 02:29:26.690000+00:00  28.225  88.163   79.1  5.5    86 km NNW of Mangan, India   usgs   4.383276   -0.487576    3.192907   \n",
       "1  1990-01-10 23:01:21.960000+00:00  26.559  86.663   68.5  4.7   8 km WNW of R?jbir?j, Nepal   usgs   4.241327   -2.153576    1.692907   \n",
       "2  1990-01-30 15:06:26.080000+00:00  28.599  85.714   52.4  4.5  74 km NNW of Kod?ri??, Nepal   usgs   3.977811   -0.113576    0.743907   \n",
       "3  1990-02-09 15:51:23.020000+00:00  29.925  80.730   33.0  4.6  20 km ENE of D?rchul?, Nepal   usgs   3.526361    1.212424   -4.240093   \n",
       "4  1990-02-21 07:21:17.300000+00:00  28.082  82.430   33.0  4.8  14 km ESE of Tuls?pur, Nepal   usgs   3.526361   -0.630576   -2.540093   \n",
       "\n",
       "   year  month_sin  month_cos  hour_sin  hour_cos  rolling_count_7d  rolling_count_30d  rolling_mean_mag_30d  days_since_last_major  \\\n",
       "0  1990   0.500000   0.866025  0.500000  0.866025                 0                  0                  0.00            3650.000000   \n",
       "1  1990   0.500000   0.866025 -0.258819  0.965926                 1                  1                  5.50               1.855501   \n",
       "2  1990   0.500000   0.866025 -0.707107 -0.707107                 0                  2                  5.10              21.525687   \n",
       "3  1990   0.866025   0.500000 -0.707107 -0.707107                 0                  2                  4.60              31.556902   \n",
       "4  1990   0.866025   0.500000  0.965926 -0.258819                 0                  2                  4.55              43.202669   \n",
       "\n",
       "   is_major  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master = pd.read_csv(\"../data/raw/nepal_seismicity_master.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", master.shape)\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2733 entries, 0 to 2732\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   dt                     2733 non-null   object \n",
      " 1   lat                    2733 non-null   float64\n",
      " 2   lon                    2733 non-null   float64\n",
      " 3   depth                  1536 non-null   float64\n",
      " 4   mag                    2733 non-null   float64\n",
      " 5   place                  2733 non-null   object \n",
      " 6   source                 2733 non-null   object \n",
      " 7   depth_log              1536 non-null   float64\n",
      " 8   lat_offset             2733 non-null   float64\n",
      " 9   lon_offset             2733 non-null   float64\n",
      " 10  year                   2733 non-null   int64  \n",
      " 11  month_sin              2733 non-null   float64\n",
      " 12  month_cos              2733 non-null   float64\n",
      " 13  hour_sin               2733 non-null   float64\n",
      " 14  hour_cos               2733 non-null   float64\n",
      " 15  rolling_count_7d       2733 non-null   int64  \n",
      " 16  rolling_count_30d      2733 non-null   int64  \n",
      " 17  rolling_mean_mag_30d   2733 non-null   float64\n",
      " 18  days_since_last_major  2733 non-null   float64\n",
      " 19  is_major               2733 non-null   int64  \n",
      "dtypes: float64(13), int64(4), object(3)\n",
      "memory usage: 427.2+ KB\n"
     ]
    }
   ],
   "source": [
    "master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.rename(columns={\n",
    "    \"dt\": \"timestamp\",\n",
    "    \"lat\": \"latitude\",\n",
    "    \"lon\": \"longitude\",\n",
    "    \"mag\": \"magnitude\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bv/mp08q1_52dz_qbs5_34gjdfr0000gn/T/ipykernel_6926/1593710061.py:1: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  master[\"timestamp\"] = pd.to_datetime(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"1994-03-08 02:05:00+00:00\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f%z\", at position 50. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m master[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_datetime_format\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m master[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/seismic-risk-analytics-nepal/venv/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:1072\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1070\u001b[39m         result = arg.map(cache_array)\n\u001b[32m   1071\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m         values = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/seismic-risk-analytics-nepal/venv/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:435\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    438\u001b[39m     arg,\n\u001b[32m    439\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    444\u001b[39m )\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    447\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/seismic-risk-analytics-nepal/venv/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:469\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    459\u001b[39m     arg,\n\u001b[32m    460\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    465\u001b[39m ) -> Index:\n\u001b[32m    466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     result, tz_out = \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    471\u001b[39m         unit = np.datetime_data(result.dtype)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:501\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:451\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:583\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime._parse_with_format\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: time data \"1994-03-08 02:05:00+00:00\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f%z\", at position 50. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "master[\"timestamp\"] = pd.to_datetime(\n",
    "    master[\"timestamp\"],\n",
    "    utc=True,\n",
    "    infer_datetime_format=True\n",
    ")\n",
    "\n",
    "master[\"timestamp\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv(\"../data/raw/nepal_seismicity_master.csv\")\n",
    "\n",
    "master = master.rename(columns={\n",
    "    \"dt\": \"timestamp\",\n",
    "    \"lat\": \"latitude\",\n",
    "    \"lon\": \"longitude\",\n",
    "    \"mag\": \"magnitude\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master[\"timestamp\"] = pd.to_datetime(\n",
    "    master[\"timestamp\"],\n",
    "    format=\"mixed\",\n",
    "    utc=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master[\"timestamp\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('1990-01-09 02:29:26.690000+0000', tz='UTC'),\n",
       " Timestamp('2025-12-07 02:43:07.342000+0000', tz='UTC'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master[\"timestamp\"].min(), master[\"timestamp\"].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "master[\"year\"] = master[\"timestamp\"].dt.year\n",
    "master[\"month\"] = master[\"timestamp\"].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated = master.dropna(subset=[\n",
    "    \"timestamp\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"magnitude\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2733, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validated.to_csv(\n",
    "    \"../data/processed/seismic_master_validated.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "validated.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
